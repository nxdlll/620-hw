---
title: "BIOSTAT 620 hm3 problem 1"
output: html_document
---
GITHUB LINK https://github.com/nxdlll/620-hw
a  Analyze the data of Project I
```{r, include=FALSE}
library(ISLR2)
library(AER)
library(knitr)
library(glmnet)
#library(lasso2)
library(ggplot2)
library(gridExtra)
library(ggpubr)
library(MASS)
library(pls)
library(Metrics)
library(faraway)
library(latex2exp)
library(psych)
library(dplyr)
library(stargazer)
library(broom)
library(GGally)
library(lmtest)
library(olsrr)
library(estimatr)
library(readxl)
library(coin)
library(torch)
library(luz)
library(torchvision)
library(torchdatasets)
library(usdm)
library(car)
library(plm)
library(gplots) 
library(fixest)
library(modelsummary)
library(Rmisc)
library("coefplot")
library("sas7bdat")
library(leaps) 
library(sandwich)
library(fastDummies)
library(caret)
library(Rcpp)
library(githubinstall)
#library(HDeconometrics)
library(pscl)
library(rsq)
library(e1071)
library(ROCR)
library(survival)
library(JM)
library(survminer)
library(mlogit)
library(openxlsx)
library(zeallot)
library(lubridate)
library(circular) 
```

### Data

**Import Data**

```{r, echo=TRUE}
data_rongji  <- read_excel("Cao.xlsx") 
data_yangme  <- read_excel("Mao.xlsx") 
data_zyzahng <- read_excel("Yang.xlsx") 
```

```{r, echo=TRUE}
# show same columns across each person

colnames(data_rongji)
colnames(data_yangme)
colnames(data_zyzahng)
```

**Data Preprocessing**

* convert ```Pickup.1st``` to an angle ranged from 0 to 360; 

```{r, echo=TRUE}
calculate_angular <- function(data, time, time_ang) {
  data[[time_ang]] <- ((hour(data[[time]]) * 60 + minute(data[[time]])) / (24 * 60) * 360)
  return(data)
}

data_rongji  <- calculate_angular(data_rongji,  "Pickup.1st", "Pickup.1st.angular")
data_yangme  <- calculate_angular(data_yangme,  "Pickup.1st", "Pickup.1st.angular")
data_zyzahng <- calculate_angular(data_zyzahng, "Pickup.1st", "Pickup.1st.angular")
```

### Federated Learning

* compute summary statistics $SSX=\sum^n_{i=1} (X_i -\bar X)^2$, $SSY=\sum^n_{i=1} (Y_i -\bar Y)^2$, $SSXY=\sum^n_{i=1} (Y_i -\bar Y)(X_i -\bar X)$ for each user; 

* each user can use ```summary_stats()``` to compute respective $SSX, SSY, SSXY$; 

```{r, echo=TRUE}
response   <- "Total.ST.min"
predictors <- c("Pickups", "Pickup.1st.angular", "hightem")

summary_stats <- function(data, response, predictors) {
  X <- as.matrix(cbind(1, data[, predictors]))
  y <- as.matrix(data[, response])
  SSX  <- t(X) %*% X
  SSY  <- t(y) %*% y
  SSXY <- t(X) %*% y
  return(list(SSX=SSX, SSY=SSY, SSXY=SSXY))
}

summary_stats_rongji  <- summary_stats(data_rongji,  response, predictors)
summary_stats_yangme  <- summary_stats(data_yangme,  response, predictors)
summary_stats_zyzahng <- summary_stats(data_zyzahng, response, predictors)
```

* ```results_fl()``` is a function on central server that returns $\hat \beta$, $RSS$, $AIC$ value, and $\text{adjusted } R^2$ after combined the summary statistics by 3 users; 

```{r, echo=TRUE}
results_fl <- function(data_1, data_2, data_3, summary_stats_1, summary_stats_2, summary_stats_3, n, p) {
  
  Beta <- solve(summary_stats_1$SSX + summary_stats_2$SSX + summary_stats_3$SSX) %*% (summary_stats_1$SSXY + summary_stats_2$SSXY + summary_stats_3$SSXY) 
  
  RSS  <- (summary_stats_1$SSY+summary_stats_2$SSY+summary_stats_3$SSY) - 2*t(Beta)%*%(summary_stats_1$SSXY+summary_stats_2$SSXY+summary_stats_3$SSXY) + t(Beta)%*%(summary_stats_1$SSX+summary_stats_2$SSX+summary_stats_3$SSX)%*%Beta
  
  AIC <- n * log(RSS) + 2 * p
  
  all_response <- c(data_1$Total.ST.min, data_2$Total.ST.min, data_3$Total.ST.min)
  TSS <- sum((all_response - mean(all_response))**2)
  adj_R_squared <- 1 - (RSS/(n-p)) / (TSS/(n-1))
  
  return(list(Beta=Beta, RSS=RSS, AIC=AIC, adj_R_squared=adj_R_squared))
}

output <- results_fl(data_rongji, data_yangme, data_zyzahng, 
                     summary_stats_rongji, summary_stats_yangme, summary_stats_zyzahng,
                     n=dim(data_rongji)[1]+dim(data_yangme)[1]+dim(data_zyzahng)[1], 
                     p=length(predictors)+1)

output
```

### Confirmation Analysis

* combine all data to fit a linear regression; 

* $\hat \beta$, $RSS$, $AIC$ value, and $\text{adjusted } R^2$ identical with the results we obtained earlier from the federated learning framework; 

```{r, echo=TRUE}
data_merge   <- rbind(data_rongji, data_yangme, data_zyzahng)

oracle_model <- lm(Total.ST.min~ Pickups + Pickup.1st.angular + hightem, data = data_merge)
summary(oracle_model)

n <- length(resid(oracle_model))
p <- length(coef(oracle_model))
AIC <- n * log(sum(resid(oracle_model)^2)) + 2 * p

cat("RSS: ", sum(resid(oracle_model)^2), "\n")
cat("AIC: ", AIC, "\n")
```


* model diagnosis and check for ```LINE```assumptions; 

```{r, echo=TRUE, fig.width=12.5, fig.height=7.5, fig.align='center'}
par(mfrow = c(2, 2))
plot(oracle_model)
```
b
the score of Functionality is 14,the score of Reliability is 12 the score of  Performance is 14,the score of Usability is 14, and score of Maintainability is 11.
the total score is 65

c this project let us code the abstract federate learning concept into real experience.my peer's cose is neat and well organized. they named the data from different data sets with the same name it is easy of us the use and prevent the error caused from different col names.but this code is lack of instruction. when a stanger us it they need to understand the meaning of ecah code chunk and rewrite some part of it to change the variables to use it. there colud have a annotate for the part people may cahnge for the convenience. 








